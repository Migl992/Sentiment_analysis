{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the dataset\n",
    "df = pd.read_csv(\"sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>880708</td>\n",
       "      <td>positive</td>\n",
       "      <td>1685677926</td>\n",
       "      <td>Sun May 03 01:31:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thereserogers</td>\n",
       "      <td>We found an apartment, whoo hoo!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>1041208</td>\n",
       "      <td>positive</td>\n",
       "      <td>1957051197</td>\n",
       "      <td>Thu May 28 23:22:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Bandworker</td>\n",
       "      <td>@bobbydeyoe i am doing great. lol Thank you. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1328334</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015502950</td>\n",
       "      <td>Wed Jun 03 04:50:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RonTaylorNL</td>\n",
       "      <td>Newfoundland spring morning, walking around Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>96091</td>\n",
       "      <td>negative</td>\n",
       "      <td>1792473817</td>\n",
       "      <td>Wed May 13 23:14:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Gailporter</td>\n",
       "      <td>@Mike_Fountain stress.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>191872</td>\n",
       "      <td>negative</td>\n",
       "      <td>1969733421</td>\n",
       "      <td>Sat May 30 01:01:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BreeSymone</td>\n",
       "      <td>i got stuck on an interesting phone call, i se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>878938</td>\n",
       "      <td>positive</td>\n",
       "      <td>1685346186</td>\n",
       "      <td>Sun May 03 00:00:10 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LittleYellowJen</td>\n",
       "      <td>@BrianMcnuggets maybe some rapping with vanill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1525985</td>\n",
       "      <td>positive</td>\n",
       "      <td>2176957826</td>\n",
       "      <td>Mon Jun 15 05:08:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>wardverstraete</td>\n",
       "      <td>is cutting some trees to improve spectator qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>299298</td>\n",
       "      <td>negative</td>\n",
       "      <td>1997968820</td>\n",
       "      <td>Mon Jun 01 17:46:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kristianmilton</td>\n",
       "      <td>feeling sick had to go home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>1589342</td>\n",
       "      <td>positive</td>\n",
       "      <td>2191221375</td>\n",
       "      <td>Tue Jun 16 04:48:10 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tormel</td>\n",
       "      <td>@forsund Congratulations!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>1459334</td>\n",
       "      <td>positive</td>\n",
       "      <td>2063744201</td>\n",
       "      <td>Sun Jun 07 03:54:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DavidJohnRees</td>\n",
       "      <td>@feblub All good here!  Stuck in work all day ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  polarity          id                          date  \\\n",
       "3848      880708  positive  1685677926  Sun May 03 01:31:14 PDT 2009   \n",
       "4060     1041208  positive  1957051197  Thu May 28 23:22:55 PDT 2009   \n",
       "1047     1328334  positive  2015502950  Wed Jun 03 04:50:09 PDT 2009   \n",
       "1727       96091  negative  1792473817  Wed May 13 23:14:36 PDT 2009   \n",
       "3800      191872  negative  1969733421  Sat May 30 01:01:48 PDT 2009   \n",
       "1614      878938  positive  1685346186  Sun May 03 00:00:10 PDT 2009   \n",
       "22       1525985  positive  2176957826  Mon Jun 15 05:08:30 PDT 2009   \n",
       "4312      299298  negative  1997968820  Mon Jun 01 17:46:13 PDT 2009   \n",
       "4660     1589342  positive  2191221375  Tue Jun 16 04:48:10 PDT 2009   \n",
       "4540     1459334  positive  2063744201  Sun Jun 07 03:54:23 PDT 2009   \n",
       "\n",
       "         query             user  \\\n",
       "3848  NO_QUERY    thereserogers   \n",
       "4060  NO_QUERY       Bandworker   \n",
       "1047  NO_QUERY      RonTaylorNL   \n",
       "1727  NO_QUERY       Gailporter   \n",
       "3800  NO_QUERY       BreeSymone   \n",
       "1614  NO_QUERY  LittleYellowJen   \n",
       "22    NO_QUERY   wardverstraete   \n",
       "4312  NO_QUERY   kristianmilton   \n",
       "4660  NO_QUERY           tormel   \n",
       "4540  NO_QUERY    DavidJohnRees   \n",
       "\n",
       "                                                  tweet  \n",
       "3848                 We found an apartment, whoo hoo!!   \n",
       "4060  @bobbydeyoe i am doing great. lol Thank you. Y...  \n",
       "1047  Newfoundland spring morning, walking around Qu...  \n",
       "1727                            @Mike_Fountain stress.   \n",
       "3800  i got stuck on an interesting phone call, i se...  \n",
       "1614  @BrianMcnuggets maybe some rapping with vanill...  \n",
       "22    is cutting some trees to improve spectator qua...  \n",
       "4312                       feeling sick had to go home   \n",
       "4660                         @forsund Congratulations!   \n",
       "4540  @feblub All good here!  Stuck in work all day ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    2542\n",
       "negative    2458\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look inside the csv, it's balanced!\n",
    "df[\"polarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Tired, grumpy and unsure what my priorities ar...\n",
       "1       Way to go dad! You're gonna be a dad for the b...\n",
       "2       completely broke but enjoying myself at the mo...\n",
       "3                                         House season 1 \n",
       "4                        @ Blizzfm thanks uda follow yaa \n",
       "5       @KhoreoKat Do you trust newspaper people?  Not...\n",
       "6       @Linny_Buck Hey Linny. I live in South Africa....\n",
       "7       @A_BlueMidnight hey! u were able to get ur ipo...\n",
       "8       @Ashley_89 you need another holiday already, h...\n",
       "9       @Renee_d i hope all is okay  not being able to...\n",
       "10      twitter u r sooooooooooooo boring even my inla...\n",
       "11      @anna_black Haha! Best compliment I've had: &q...\n",
       "12      @malu__ haven't spoke Marielle for a lon long ...\n",
       "13      Kinda missed it here, but Happy Birthday Tetris! \n",
       "14                       Got to see my bestftiend 2nite. \n",
       "15      @ThisisDavina Hi!! Cannot wait till BB starts ...\n",
       "16      http://twitpic.com/6uttq - In the beach I love...\n",
       "17                         @EmbryC  We'll miss you Embry \n",
       "18                                   @shamim86 come back \n",
       "19                                         time for work \n",
       "20      Goodnight to an amazing day. Minus the fact th...\n",
       "21      @Makenzesgranna Why can't the rain only wet th...\n",
       "22      is cutting some trees to improve spectator qua...\n",
       "23      @heynadine hey hey, i really hope you enter me...\n",
       "24                   @thelele lucky! Its sooo hawt heyah \n",
       "25      Don't wanna go out. Hoping plans get cancelled...\n",
       "26      i just saw something that  really walla walla ...\n",
       "27      life got me restless. i guess its all about th...\n",
       "28      @JillianMichaels Hi! I`m buying a fitness-game...\n",
       "29      @MrsPinkyIvory ; aww pinky  I'll keep you in m...\n",
       "                              ...                        \n",
       "4970    @TwinkleTessa theyre not coming  they were her...\n",
       "4971    @epiphanygirl  lol check u out... superstar st...\n",
       "4972    were driving by Wonderland right now! makes me...\n",
       "4973    Trying to get a root folder name with #Nintex ...\n",
       "4974    @aisle4Records yeh i spose we have big day out...\n",
       "4975     last monday of junior year! last week of school \n",
       "4976    waiting for my mother to wake her ass up , so ...\n",
       "4977    @jpcashcash aww i hope you feel better  &lt;33...\n",
       "4978    @rpartain @josh909 @DDsD @craigthomler Thanks ...\n",
       "4979    @BabyKayCee I've known people who have managed...\n",
       "4980                                    Back to VA today \n",
       "4981                 @Ellen_Stafford You need an oreck  x\n",
       "4982             i can't breatheee... i hate being sick! \n",
       "4983                 @LittleMissHaya awekay kewl. thanx. \n",
       "4984      I only have 2 more seasons of X-Files to watch \n",
       "4985    #squarespace has yet to give me my free iPhone...\n",
       "4986    is about to take his first shower in 2 days  t...\n",
       "4987    @ oh yeah then we can hang out!! i been busy l...\n",
       "4988    @JoeJonas1Fan1 i love fly with me  especially ...\n",
       "4989    @a10tionadiq lol mybad  i had PJ's on when i f...\n",
       "4990    Adrian askew the General Secretary is retiring...\n",
       "4991    Just made friends with the metal detector dude...\n",
       "4992    @oliverpayne Pretty much the same as us randy ...\n",
       "4993                           The week is finally over! \n",
       "4994    @alwayscoffee With this economy, I imagine onl...\n",
       "4995    mwahaha! today should be a good day, i have st...\n",
       "4996    Twitter withdraw finally over.. Welcome back t...\n",
       "4997    @radioactive_ Aha no problem,  thanks for foll...\n",
       "4998    @ImaginaryDuck save me minh  i seriously dread...\n",
       "4999                             missin my baby in texas \n",
       "Name: tweet, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's create the variables\n",
    "#texts:tweets texts\n",
    "texts = df[\"tweet\"]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       negative\n",
       "1       positive\n",
       "2       positive\n",
       "3       positive\n",
       "4       positive\n",
       "5       positive\n",
       "6       positive\n",
       "7       positive\n",
       "8       negative\n",
       "9       positive\n",
       "10      negative\n",
       "11      negative\n",
       "12      negative\n",
       "13      positive\n",
       "14      positive\n",
       "15      positive\n",
       "16      positive\n",
       "17      negative\n",
       "18      negative\n",
       "19      positive\n",
       "20      negative\n",
       "21      positive\n",
       "22      positive\n",
       "23      positive\n",
       "24      negative\n",
       "25      negative\n",
       "26      negative\n",
       "27      negative\n",
       "28      positive\n",
       "29      negative\n",
       "          ...   \n",
       "4970    negative\n",
       "4971    positive\n",
       "4972    negative\n",
       "4973    positive\n",
       "4974    negative\n",
       "4975    positive\n",
       "4976    positive\n",
       "4977    negative\n",
       "4978    positive\n",
       "4979    positive\n",
       "4980    negative\n",
       "4981    positive\n",
       "4982    negative\n",
       "4983    positive\n",
       "4984    negative\n",
       "4985    negative\n",
       "4986    positive\n",
       "4987    positive\n",
       "4988    positive\n",
       "4989    negative\n",
       "4990    negative\n",
       "4991    positive\n",
       "4992    positive\n",
       "4993    positive\n",
       "4994    negative\n",
       "4995    positive\n",
       "4996    negative\n",
       "4997    positive\n",
       "4998    negative\n",
       "4999    negative\n",
       "Name: polarity, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y:polarity of tweets\n",
    "y = df[\"polarity\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11619 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are going to vectorize the tweets, bcs for the model we need  numeric array and not texts\n",
    "#first we crate the vectorizator that will create an index of all the words inside the tweets texts\n",
    "vect = CountVectorizer()\n",
    "vect.fit(texts)\n",
    "#and now let's create the vectorizated tweets in the variable X\n",
    "X =vect.transform(texts)\n",
    "X[:3]\n",
    "#we can see that this 3 texts are now arrays with 11619 elements with 3 element market as presented in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see them in extension\n",
    "X[:3].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3750, 11619), (1250, 11619))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's set the validation, so we will divide the dataset in 2: the train and the test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#we can check the size of the train\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create the model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's do to the model the imput for input an output and let's train him\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['negative', 'negative', 'positive', ..., 'negative', 'positive',\n",
       "        'positive'], dtype=object),\n",
       " array(['positive', 'negative', 'positive', ..., 'negative', 'positive',\n",
       "        'negative'], dtype=object))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see the prediction and accuracy\n",
    "p_train = model.predict(X_train)\n",
    "p_test = model.predict(X_test)\n",
    "p_test, p_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = accuracy_score(y_train, p_train)\n",
    "acc_test = accuracy_score(y_test, p_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96933333333333338"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the accuracy of the train will be really high bcs ofc is the train, so the model will \"copy\" and not really learn\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68799999999999994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the accuracy of the test instead is the real accuracy of the model\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's test the model with random text from the Donald trump account\n",
    "new_texts_Donald = {\n",
    "    \"Twitter is doing nothing about all of the lies & propaganda being put out by China or the Radical Left Democrat Party. They have targeted Republicans, Conservatives & the President of the United States. Section 230 should be revoked by Congress. Until then, it will be regulated!\",\n",
    "    \"I canâ€™t stand back & watch this happen to a great American City, Minneapolis. A total lack of leadership. Either the very weak Radical Left Mayor, Jacob Frey, get his act together and bring the City under control, or I will send in the National Guard & get the job done right\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x11619 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 63 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's vectorize them\n",
    "new_X = vect.transform(new_texts_Donald)\n",
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see if they are positive or negative\n",
    "model.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53985553,  0.46014447],\n",
       "       [ 0.03206155,  0.96793845]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can also see what is the probability of the prediction of the 2 new tweets\n",
    "model.predict_proba(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number on the right are de % of positivness and on the left of negativness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tashadoe',\n",
       " 'tasking',\n",
       " 'tasks',\n",
       " 'taste',\n",
       " 'tastes',\n",
       " 'tasty',\n",
       " 'tat',\n",
       " 'tate',\n",
       " 'tatoo',\n",
       " 'tattoo',\n",
       " 'tattooed',\n",
       " 'tattoos',\n",
       " 'taught',\n",
       " 'tax',\n",
       " 'taxi',\n",
       " 'taxpayers',\n",
       " 'taylor',\n",
       " 'taylormoll',\n",
       " 'taylorswift13',\n",
       " 'tb']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can see the positivnees or negativvness of all the words in the model\n",
    "vect.get_feature_names()[10000:10020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coeff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
